name: Job Scraper

on:
  schedule:
    # Run every 2 hours
    - cron: "0 */2 * * *"
  workflow_dispatch: # Allow manual triggering

jobs:
  scrape-jobs:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y libnss3-dev libatk-bridge2.0-dev libdrm2 libxkbcommon0 libxcomposite1 libxdamage1 libxrandr2 libgbm1 libxss1 libasound2t64
    
    - name: Install Python dependencies
      run: |
        cd scraper
        pip install -r requirements.txt
        playwright install chromium
    
    - name: Run scraper
      run: |
        cd scraper
        python scrape_jobs.py
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Check for changes
      id: verify-changed-files
      run: |
        if [ -n "$(git status --porcelain data/jobs.csv)" ]; then
          echo "changed=true" >> $GITHUB_OUTPUT
        else
          echo "changed=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Commit and push changes
      if: steps.verify-changed-files.outputs.changed == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        timestamp=$(date '+%Y-%m-%d %H:%M:%S UTC')
        git add data/jobs.csv
        git commit -m "update jobs.csv [$timestamp]"
        git push
